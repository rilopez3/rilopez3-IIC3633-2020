<h2>Multi-Armed Recommender System Bandit Ensembles</h2>

En el artículo, los autores Cañamares, Redondo y Castells, presentan un enfoque novedoso para construir un sistema de recomendación hibrido dinámico, en el análisis toman como punto de inicio los sistemas clásicos de recomendación, para los cuales detallan una crítica interesante, ya que los describen como sistemas estáticos, para los cuales se espera encontrar una política de recomendación y utilizarla de manera repetitiva sobre el usuario. Aunque los últimos años ha florecido la idea de construir sistemas híbridos, en los cuales una metodología fortalezca las debilidades de otro sistema, el producto final sigue siendo estático.  En este punto es en el cual describen que el proceso de recomendación debería ser algo dinámico, que evolucione y se adapte a través del tiempo, evolución en la cual el peso o importancia de cada modelo de recomendación debe ser dinámico.  

La crítica propuesta resulta interesante, y nos invita a cuestionar la herramienta que esperamos desarrollar, pese a que la idea básica de un sistema de recomendación es entregar un cierto grado de personalización al usuario, hemos estado excluyendo el efecto del tiempo, hemos olvidado que el sistema debe evolucionar en la medida que tenga más información del usuario.  

Para el modelo propuesto, aplicaron el enfoque de “Multi-Armed Bandit” (bandido de brazos múltiples), en el cual un usuario tomador de decisión debe decidir qué brazo o método de recomendación usar (similar a los brazos de múltiples máquinas de azar), para los cuales se debe considerar el resultado que se ha obtenido en las iteraciones pasadas. Este enfoque permite que el tomador de decisión considere las expectativas que tiene de cada modelo, lo cual genera un grado de dinamismo en la medida que las expectativas van cambiando a través del tiempo, esto nos permite evaluar como los componentes se deben adaptar en la medida que se cuenta con más información del usuario y sus preferencias.  

Los experimentos los realizaron de manera offline, partiendo de una cantidad reducida de datos (5% de la muestra), de manera iterativa durante 200 épocas ofrecieron al usuario escoger un método (la simulación utiliza una función esperada para describir la expectativa en cada iteración), luego de escoger una opción presentan la recomendación y dado el resultado de esta se ajustan las funciones de expectativa. De los resultados provistos, se aprecia que el modelo hibrido evolutivo que proponen logra superar a otros modelos híbridos estáticos, y modelos puros personalizados y no-personalizados.  

Para la inicialización de las funciones de expectativa utilizaron dos opciones del estado del arte: “Thompson sampling bandit” y “ε-greedy bandit”, los cuales les permitieron probar opciones distintas para separar las etapas de exploración de opciones, de las de explotación. Es interesante que, en los dos escenarios, el método de most-popular tiene un fuerte efecto al inicio y en la medida que se ha logrado recolectar bastante información un modelo de factorización matricial lo releva. En análisis se discute, como el uso de most-popular acelera la recolección de preferencias para un método personalizado y como este último termina logrando un mejor ajuste a través del tiempo.  

El hecho de que most-popular sea relevado, creo que se puede explicar mejor por las características mismas del listado de artículos populares, debido a que este listado es limitado, se escogen solo los artículos más populares, lista que tiene un efecto decreciente, a diferencia del listado personalizado que tiene un tamaño mayor y tasas crecientes de efectividad.  

Si bien la propuesta de un modelo hibrido evolutivo es interesante, es cuestionable la cantidad de interacciones que requiere para evolucionar, de los gráficos provistos se puede apreciar que, incluso introduciendo una variación en las funciones, existe un punto crítico similar. Un aporte interesante al experimento seria utilizar de mejor forma el resultado de las recomendaciones; dado que se conoce el conjunto de elecciones futuras (el set completo), se podría inferir por que se rechazan los artículos mal recomendados, esto con el fin de entender la lógica errónea que influyo en la recomendación, esto podría entregar un nivel de refuerzo al aprendizaje para identificar de mejor forma las funciones de expectativa.   

Si bien el producto final es un modelo online que evolucione con cada usuario de manera individual, el entender la evolución de lógicas errónea a través del tiempo, permitiría que el modelo castigue la lógica de recomendación y no el sistema. Esto se vuelve interesante en un modelo de factorización matricial, ya que nos ayudaría a entender como los factores se vuelven relevantes a través del tiempo, una evolución temporal de los hiper-parametros.

En resumen, la critica que se presenta en la lectura es muy interesante, el proceso de recomendar como sistema dinámico versus una herramienta estática, pero creo que el enfoque evolutivo se puede impulsar aún más que solo de la forma planteada.


<hr>
<h4>Rodrigo López A.</h4>
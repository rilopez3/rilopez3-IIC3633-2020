<h2>Comentarios sobre “Document Clustering Based On Non-negative Matrix Factorization"</h2>
<p>En este artículo, del año 2003, los autores nos presentan un método de agrupación de documentos, el cual, a diferencia de los métodos disponibles en ese momento, se vale de un cambio de approach para agregar mayor expresividad a los algoritmos de agrupación existentes.</p> 
<p>El modelo propuesto es del tipo document partitioning y utiliza como base lo conceptos de SVD, con la salvedad que asume el uso de una factorización matricial no negativa (NMF) y que los vectores no son ortogonales, estos supuestos los fundan sobre la base de que, al agrupar documentos sobre sus tópicos centrales, estos poseen un grado mayor de overlapping, a diferencia que cuando se utiliza SVD sobre otros contenidos. Otros tipos de técnicas, del tipo bottom-up, han utilizado este grado de overlapping para construir una jerarquía de conceptos, la cual, si bien ha resultado efectiva, es difícil de escalar por el grado de complejidad computacional. El buen resultado de estas técnicas, les sirve de base a los autores para describir que no es necesario usar el supuesto de vectores ortogonales para la agrupación de documentos.</p>
<p>Al comparar NMF con SVD, se puede notar que NMF permite que los clusters sean más definidos, lo cual es posible de observar en los gráficos comparativos que muestran los autores (con reducción dimensional) entre el uso de NMF y SVD, el hecho de que los clusters estén mejor definidos y separados en los ejes, entrega un cierto grado de certeza sobre su precisión, los centroides están lo suficientemente alejados y definidos.</p>
<p>Los autores utilizan dos métricas de desempeño para evaluar el algoritmo, Accuracy (AC) y Normalized Mutual Information Metric (MI), sobre dos dataset, TDT2 y Reuters, en ambos datasets se compara el NMF y NMF-NCW (una versión ajustada de NFM con normalización de las matrices), contra dos algoritmos del estado del arte, en ambos datasets NMF alcanza los niveles de estos algoritmos y NMF-NCW logra superarlos.</p>
<p>En la implementación, me llamo la atención que no se entreguen muchos detalles sobre el cómo se identifica el tema central (axis) de los documentos, no se entregan detalles si se utiliza un embedding particular o un método one-hot. Claramente el uso de un mejor embedding permitiría realizar una mejor identificación de conceptos similares, sinónimos, lo cual afecta la elección de mejores axis para la identificación de los overlapping y las features latentes (de carácter jerárquico en este caso).</p>
<p>En términos de aprendizaje, me llamo la atención como en el diseño de un sistema basados en contenido, el contenido es importante, pero es clave la inclusión de características de la estructura de este, relaciones jerárquicas, de orden o magnitud, entre otros, muchas uno suele conocer o tener nociones de estas características, pero se desconoce el impacto que tienen en el resultado. De manera clásica uno espera que ser capaz de describir el contenido de un documento es suficiente para mejorar su búsqueda o vinculación con otros documentos, tal como sucede con el uso de keywords, lo cual no es suficiente.</p>
<p>Respecto al uso de keywords me gusto el hecho de los autores sean críticos y reconozcan que no son suficientes y es necesario recorrer el cuerpo del documento para encontrar un mejor conjunto de datos, lamentablemente no se entrega información estadística de este proceso, lo cual se vuelve importante si se considera que aplicar la metodología sobre noticias de tamaño ajustado es factible, pero realizar la misma tarea en un documento de mayor envergadura se vuelve poco viable, tampoco se mencionan pruebas sobre este tipo de documentos o la posibilidad de usar directamente el abstract de los documentos, los cuales se podrían definir como buenos descriptores del contenido, entregados por el mismo autor.</p>

<h4>Rodrigo López A.</h4>

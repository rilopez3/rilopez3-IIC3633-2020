<h2>Comentarios sobre “BPR: Bayesian Personalized Ranking from Implicit Feedback"</h2>
<p>Rendle, Freudenthaler, Gantner y Schmidt-Thieme, en su artículo “BPR: Bayesian Personalized Ranking from Implicit Feedback”, del año 2009, presentan un nuevo criterio de optimización para modelos de recomendación basados en feedback implícito BPR-Opt, el modelo se basa en un análisis bayesiano del problema de recomendar una lista ordenada de artículos personalizada al usuario. Los autores acompañan el criterio con un algoritmo de aprendizaje diseñado para optimizar modelos respecto a BPR-OPT, proponen LEARNBPR como método de aprendizaje que utiliza un descenso de gradiente estocástico con bootstrap sampling.</p>
<p>Para este método de aprendizaje LEARNBPR, se demuestra que optimiza el descenso de gradiente para el problema de recomendaciones personalizadas, y muestran el resultado de su implementación en los dos modelos que definían el estado del arte al momento de su publicación, kNN y factorización matricial, en ambos casos el proceso de aplicar el cambio de criterio supera los resultados de otras opciones.</p>
<p>En este articulo, me llamo la atención la fuerza con la que los autores critican los criterios de optimización utilizados en los modelos kNN y factorización matricial, donde explican que estos solo se enfocaban en predecir si un ítem en particular seria seleccionado o no, por un usuario determinado, pero no se preocupaban de mejorar los parámetros que le permiten generar un ranking de recomendaciones. De manera rápida, describen que los criterios utilizados hasta ese momento tenían problemas de sobreajuste, que los investigadores intentaban controlar, que sus métodos dejaron de preocuparse por el ranking de los artículos recomendados, lo cual claramente afecta la calidad de las recomendaciones realizadas.</p>
<p>El criterio de optimización propuesto BPR-Opt, es descrito como un criterio que se enfoca en entregar un ranking de ítems a cada usuario, proponiéndolo como un verdadero criterio de optimización personalizado. Esta aseveración, la realizan sobre la base de que el proceso de evaluar como preferencias, aquellos contenidos que presentaban algún grado de interés por parte del usuario, observación, compra o simple lectura, sin definir un grado de jerarquía u orden, por sobre los contenidos no observados, dificulta el proceso de aprendizaje del criterio de optimización. Para los cuales, los algoritmos de descenso de gradiente utilizados tienen bajas velocidades de convergencia, produciendo recomendaciones de baja calidad.</p>
<p>Como contrapropuesta a los métodos utilizados, los autores presentan una definición distinta de los artículos preferidos, en esta nueva definición los artículos definen su preferencia con respecto al resto de artículos o contenidos que no son observados o consumidos, considerando feedback implicito. Esta relación de superioridad, de un articulo por sobre otro de manera asimétrica, les permite definir relaciones de transitividad entre los artículos, que ayudan a que los parámetros aprendan de mejor forma las preferencias del usuario.</p>
<p>En un análisis inicial de la propuesta, cuesta comprender el efecto de generar esta preferencia, en el articulo se describe de manera matemática la relación de orden que se construye sobre los artículos, al utilizar solo definiciones matemáticas, y se requiere de una tercera o cuarta lectura para entender el efecto que tienen en la recomendacion y en la velocidad de convergencia del gradiente. En el artículo, creo que existe un fuerte enfoque en demostrar matematicamente el impacto del criterio, olvidando incluso que su crítica es hacia las recomendaciones que no están siendo personalizadas.</p>
<p>Una vez se comprende la importancia de esta relación transitiva, que se termina produciendo para cada usuario, es posible apreciar el porque las recomendaciones que utilizan este tipo de aproximación realizarían verdaderas recomendaciones personalizadas, las cuales según indican los autores requiere una reducida cantidad de observaciones.</p>
<p>Para demostrar la superioridad del criterio, los autores presentan el algoritmo LEARNBPR para implementar el criterio BPR en otros modelos, lo cual realizan en los métodos kNN y factorización matricial, demostrando tener una mejor convergencia de gradiente, aportando un gran avance al estado del arte dado que este algoritmo es posible de utilizar en otros métodos, mejorando sustancialmente los resultados.</p> 
<p>En términos generales, el articulo realiza un cambio de paradigma al evaluar las recomendaciones, dado que cambia el foco de discusión, desde una predicción entre un usuario y un conjunto de artículos que ya ha consumido y sobre los cuales se busca encontrar un nuevo artículo similar, hacia una predicción de orden de preferencias, un enfoque donde los artículos con los cuales no se ha interactuado entregan información sobre el consumo y las elecciones del usuario.</p> 
<h4>Rodrigo López A.</h4>
